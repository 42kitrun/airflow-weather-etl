from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import requests
import os
import psycopg2

# â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

API_KEY = os.environ.get('OPENWEATHER_API_KEY')  # .envì—ì„œ ê°€ì ¸ì˜´
DB_CONN = "postgresql://airflow:airflow@postgres/airflow"
BASE_URL = "https://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst"

# ë„ì‹œë³„ ê²©ìž ì¢Œí‘œ
CITIES = [
    {'name': 'Seoul', 'nx': 60, 'ny': 127},
    {'name': 'Busan', 'nx': 98, 'ny': 76},
    {'name': 'Jeju',  'nx': 52, 'ny': 38},
]


# â”€â”€ Task 1: Extract â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ìƒì²­ API í˜¸ì¶œ â†’ raw ì‘ë‹µì„ XComì— ì €ìž¥
def extract(**context):
    # APIëŠ” ì •ì‹œ ê¸°ì¤€ì´ë¼ í˜„ìž¬ ì‹œê°ì—ì„œ 1ì‹œê°„ ì „ì„ base_timeìœ¼ë¡œ ì‚¬ìš©
    now = datetime.now() - timedelta(hours=1)
    base_date = now.strftime('%Y%m%d')
    base_time = now.strftime('%H00')

    results = []
    for city in CITIES:
        params = {
            'serviceKey': API_KEY,
            'numOfRows': 10,
            'pageNo': 1,
            'dataType': 'JSON',
            'base_date': base_date,
            'base_time': base_time,
            'nx': city['nx'],
            'ny': city['ny'],
        }
        response = requests.get(BASE_URL, params=params)
        response.raise_for_status()
        data = response.json()

        # API ì˜¤ë¥˜ ì²´í¬
        result_code = data['response']['header']['resultCode']
        if result_code != '00':
            raise ValueError(f"{city['name']} API ì˜¤ë¥˜: {data['response']['header']['resultMsg']}")

        results.append({
            'city': city['name'],
            'items': data['response']['body']['items']['item'],
            'base_date': base_date,
            'base_time': base_time,
        })

    context['ti'].xcom_push(key='raw_data', value=results)
    print(f"âœ… {len(results)}ê°œ ë„ì‹œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({base_date} {base_time})")


# â”€â”€ Task 2: Transform â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# category ë°°ì—´ â†’ í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œí•´ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
def transform(**context):
    raw_data = context['ti'].xcom_pull(key='raw_data')

    transformed = []
    for entry in raw_data:
        # category ë°°ì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        # [{'category': 'T1H', 'obsrValue': '13.1'}, ...] â†’ {'T1H': '13.1', ...}
        cat = {item['category']: item['obsrValue'] for item in entry['items']}

        transformed.append({
            'city':       entry['city'],
            'base_date':  entry['base_date'],
            'base_time':  entry['base_time'],
            'temp':       float(cat.get('T1H', 0)),   # ê¸°ì˜¨ (â„ƒ)
            'humidity':   int(cat.get('REH', 0)),      # ìŠµë„ (%)
            'wind_speed': float(cat.get('WSD', 0)),    # í’ì† (m/s)
            'rain_type':  int(cat.get('PTY', 0)),      # ê°•ìˆ˜í˜•íƒœ (0=ì—†ìŒ, 1=ë¹„, 3=ëˆˆ)
            'rain_1h':    float(cat.get('RN1', 0)),    # 1ì‹œê°„ ê°•ìˆ˜ëŸ‰ (mm)
        })

    context['ti'].xcom_push(key='transformed_data', value=transformed)
    print(f"âœ… ë³€í™˜ ì™„ë£Œ: {transformed}")


# â”€â”€ Task 3: Load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë³€í™˜ëœ ë°ì´í„°ë¥¼ PostgreSQLì— ì €ìž¥
def load(**context):
    data = context['ti'].xcom_pull(key='transformed_data')

    conn = psycopg2.connect(DB_CONN)
    cur = conn.cursor()

    for row in data:
        cur.execute("""
            INSERT INTO weather_raw
                (city, temp_celsius, humidity, wind_speed, rain_type, rain_1h, collected_at)
            VALUES (%s, %s, %s, %s, %s, %s, NOW())
        """, (row['city'], row['temp'], row['humidity'], row['wind_speed'], row['rain_type'], row['rain_1h']))

    conn.commit()
    cur.close()
    conn.close()
    print(f"âœ… {len(data)}ê°œ ë„ì‹œ ë°ì´í„° DB ì €ìž¥ ì™„ë£Œ")


# â”€â”€ Task 4: Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¼ê°„ í†µê³„ ì €ìž¥
def report(**context):
    conn = psycopg2.connect(DB_CONN)
    cur = conn.cursor()

    today = datetime.now().date()

    for city in CITIES:
        cur.execute("""
            INSERT INTO weather_daily_stats (city, stat_date, avg_temp, max_temp, min_temp, avg_humidity)
            SELECT city, %s,
                   ROUND(AVG(temp_celsius), 2),
                   MAX(temp_celsius),
                   MIN(temp_celsius),
                   AVG(humidity)::int
            FROM weather_raw
            WHERE city = %s AND DATE(collected_at) = %s
            GROUP BY city
            ON CONFLICT (city, stat_date) DO UPDATE
              SET avg_temp     = EXCLUDED.avg_temp,
                  max_temp     = EXCLUDED.max_temp,
                  min_temp     = EXCLUDED.min_temp,
                  avg_humidity = EXCLUDED.avg_humidity
        """, (today, city['name'], today))

    conn.commit()
    cur.close()
    conn.close()
    print(f"âœ… ì¼ê°„ í†µê³„ ì €ìž¥ ì™„ë£Œ")


# â”€â”€ Task 5: Notify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Slackìœ¼ë¡œ ê²°ê³¼ ì•Œë¦¼ (SLACK_WEBHOOK_URL ì—†ìœ¼ë©´ ìŠ¤í‚µ)
def notify(**context):
    webhook_url = os.environ.get('SLACK_WEBHOOK_URL')
    if not webhook_url:
        print("âš ï¸ SLACK_WEBHOOK_URL ì—†ìŒ - ì•Œë¦¼ ìŠ¤í‚µ")
        return

    data = context['ti'].xcom_pull(key='transformed_data')

    rain_label = {0: 'ì—†ìŒ', 1: 'ë¹„', 2: 'ë¹„/ëˆˆ', 3: 'ëˆˆ', 5: 'ë¹—ë°©ìš¸', 6: 'ë¹—ë°©ìš¸/ëˆˆë‚ ë¦¼', 7: 'ëˆˆë‚ ë¦¼'}
    message = "ðŸŒ¤ *ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ìˆ˜ì§‘ ì™„ë£Œ*\n"
    for row in data:
        rain = rain_label.get(row['rain_type'], 'ì•Œìˆ˜ì—†ìŒ')
        message += f"â€¢ {row['city']}: {row['temp']}â„ƒ, ìŠµë„ {row['humidity']}%, ê°•ìˆ˜ {rain}\n"

    requests.post(webhook_url, json={"text": message})
    print("âœ… Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")


# â”€â”€ DAG ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with DAG(
    dag_id='weather_etl',
    default_args=default_args,
    start_date=datetime(2026, 1, 1),
    schedule='@hourly',     # ë§¤ì‹œê°„ ì‹¤í–‰ (ê¸°ìƒì²­ ì´ˆë‹¨ê¸°ì‹¤í™©ì€ 1ì‹œê°„ ë‹¨ìœ„)
    catchup=False,
    tags=['weather', 'etl'],
) as dag:

    t1 = PythonOperator(task_id='extract',   python_callable=extract)
    t2 = PythonOperator(task_id='transform', python_callable=transform)
    t3 = PythonOperator(task_id='load',      python_callable=load)
    t4 = PythonOperator(task_id='report',    python_callable=report)
    t5 = PythonOperator(task_id='notify',    python_callable=notify)

    t1 >> t2 >> t3 >> t4 >> t5